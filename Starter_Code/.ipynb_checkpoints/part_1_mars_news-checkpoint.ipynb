{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set up the splinter\n",
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars news site](https://static.bc-edx.com/data/web/mars_news/index.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars news site: https://static.bc-edx.com/data/web/mars_news/index.html\n",
    "url = 'https://static.bc-edx.com/data/web/mars_news/index.html'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "#the two elements we are looking for are titles and previews , the div classes are as follows\n",
    "#TITLE = <div class=\"content_title\"\n",
    "#PREVIEW = <div class=\"article_teaser_body\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Scrape the Website\n",
    "\n",
    "#Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "#soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the text elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\", \n",
    "   'preview': \"For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "articles_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to perform the web scraping\n",
    "def get_summary():\n",
    "    # Collect the HTML from the browser\n",
    "    html = browser.html\n",
    "    # Parse the HTML with Beautiful Soup\n",
    "    soup_object = soup(html, 'html.parser')\n",
    "    \n",
    "    # Save the main area of the web page to a variable\n",
    "    main_area = soup_object.find(\"div\", id_=\"news\", class_=\"container\")\n",
    "    \n",
    "    # Find all the articles in the main area of the web page\n",
    "    articles = main_area.find_all(\"div\", class_=\"col-md-12\")\n",
    "    \n",
    "    \n",
    "    ## CURRENT ISSUE IS FINDING THE RIGHT PATH FOR COLLECTING ALL ARTICLES, \n",
    "    ##BEST SO FAR IS JUST ONE ARTICLE BEING PULLED\n",
    "    \n",
    "    # Loop through the articles\n",
    "    for article in articles:\n",
    "        # Collect the article title\n",
    "        header = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        # Collect the article preview\n",
    "        \n",
    "        #THIS IS THE PROBLEM AREA, I\"VE TRIED CLASS= ROW\n",
    "        #CLASS= COL-MD-12\n",
    "        #CLASSH COL-MD-8\n",
    "        preview = article.find(\"div\", class_=\"col-md-12\").text.strip()\n",
    "        # Remove the underscore from the date\n",
    "        #date = date.replace('_', '')\n",
    "        \n",
    "        # Create the summary dictionary\n",
    "        summary_dict = {\n",
    "            \"header\": header,\n",
    "            \"preview\": preview\n",
    "        }\n",
    "        # Append the summary dictionary to the list\n",
    "        articles_list.append(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mget_summary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m main_area \u001b[38;5;241m=\u001b[39m soup_object\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, id_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Find all the articles in the main area of the web page\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m articles \u001b[38;5;241m=\u001b[39m \u001b[43mmain_area\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-md-12\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Loop through the articles\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m articles:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Collect the article title\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'header': \"NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\",\n",
       "  'preview': 'For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the text elements\n",
    "# Extract the title and preview text from the elements\n",
    "# Store each title and preview pair in a dictionary\n",
    "# Add the dictionary to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list to confirm success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
